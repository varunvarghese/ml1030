{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/af/849edf14d573eba9c8082db898ff0d090428d9485371cc4fe21a66717ad2/wordcloud-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (361kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 983kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting numpy>=1.6.1 (from wordcloud)\n",
      "  Using cached https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pillow (from wordcloud)\n",
      "  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 415kB/s eta 0:00:01    80% |█████████████████████████▋      | 1.6MB 33.9MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy, pillow, wordcloud\n",
      "Successfully installed numpy-1.16.2 pillow-5.4.1 wordcloud-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/varun/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"../data/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1419</td>\n",
       "      <td>38924112</td>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>11308465</td>\n",
       "      <td>Marcela</td>\n",
       "      <td>Having the opportunity of arriving to Alexandr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419</td>\n",
       "      <td>44791978</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>9580285</td>\n",
       "      <td>Marco</td>\n",
       "      <td>We have no enough words to describe how beauty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1419</td>\n",
       "      <td>45957133</td>\n",
       "      <td>2015-09-07</td>\n",
       "      <td>38394721</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>The listing was exceptional and an even better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1419</td>\n",
       "      <td>67295154</td>\n",
       "      <td>2016-03-28</td>\n",
       "      <td>3515044</td>\n",
       "      <td>Shaun</td>\n",
       "      <td>Alexandra's home was amazing and in such a nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1419</td>\n",
       "      <td>177702208</td>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>13987100</td>\n",
       "      <td>Kate</td>\n",
       "      <td>Beautiful home. Very comfortable and clean. Pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id         id        date  reviewer_id reviewer_name  \\\n",
       "0        1419   38924112  2015-07-19     11308465       Marcela   \n",
       "1        1419   44791978  2015-08-29      9580285         Marco   \n",
       "2        1419   45957133  2015-09-07     38394721        Andrea   \n",
       "3        1419   67295154  2016-03-28      3515044         Shaun   \n",
       "4        1419  177702208  2017-08-03     13987100          Kate   \n",
       "\n",
       "                                            comments  \n",
       "0  Having the opportunity of arriving to Alexandr...  \n",
       "1  We have no enough words to describe how beauty...  \n",
       "2  The listing was exceptional and an even better...  \n",
       "3  Alexandra's home was amazing and in such a nea...  \n",
       "4  Beautiful home. Very comfortable and clean. Pe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"that'll\",\n",
       " 'hadn',\n",
       " \"mightn't\",\n",
       " 'couldn',\n",
       " 'aren',\n",
       " 'what',\n",
       " 'with',\n",
       " 'because',\n",
       " 'am',\n",
       " 'then']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stopwords_set)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Having',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'of',\n",
       " 'arriving',\n",
       " 'to',\n",
       " \"Alexandra's\",\n",
       " 'house,',\n",
       " 'describes',\n",
       " 'that']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.iloc[0][\"comments\"].split(\" \")[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = reviews.iloc[0][\"comments\"].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_cleaned = [w for w in wordlist if w not in list(stopwords_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'\\r\\n': 1,\n",
       "          'Alex': 1,\n",
       "          \"Alexandra's\": 1,\n",
       "          'And': 1,\n",
       "          'Best': 1,\n",
       "          'Dundas': 1,\n",
       "          'God.': 1,\n",
       "          'Having': 1,\n",
       "          'Queen': 1,\n",
       "          'THANKS': 1,\n",
       "          'The': 2,\n",
       "          'We': 2,\n",
       "          'arriving': 1,\n",
       "          'beautiful': 1,\n",
       "          'beautiful,': 1,\n",
       "          'blessed': 1,\n",
       "          'calm': 1,\n",
       "          'clean.': 1,\n",
       "          'comfortable': 1,\n",
       "          'describes': 1,\n",
       "          'easy': 1,\n",
       "          'equippied,': 1,\n",
       "          'ever.': 1,\n",
       "          'family': 1,\n",
       "          'family.': 1,\n",
       "          'feel': 1,\n",
       "          'felt': 1,\n",
       "          'happy': 1,\n",
       "          'home.': 1,\n",
       "          'host.': 1,\n",
       "          'house': 1,\n",
       "          'house,': 1,\n",
       "          'mantain': 1,\n",
       "          'mega': 1,\n",
       "          'moments': 1,\n",
       "          'near': 1,\n",
       "          'neigbourhood': 1,\n",
       "          'one': 1,\n",
       "          'opportunity': 1,\n",
       "          'other.': 1,\n",
       "          'pretty,': 1,\n",
       "          'side': 1,\n",
       "          'stay': 1,\n",
       "          'streets:': 1,\n",
       "          'super': 2,\n",
       "          'tidy': 1,\n",
       "          'two': 1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(words_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Naive Bayes classifier\n",
    "training_set = nltk.classify.apply_features(extract_features,tweets)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
